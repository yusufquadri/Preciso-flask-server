regexp_span_tokenize
chain
range
LazySubsequence
TabTokenizer
compat
PickleCorpusView
toktok
load
ToktokTokenizer
blankline_tokenize
sent_tokenize
StanfordSegmenter
PunktSentenceTokenizer
BlanklineTokenizer
treebank
SExprTokenizer
moses
reduce
FileSystemPathPointer
read_alignedsent_block
repp
SpaceTokenizer
read_sexpr_block
read_line_block
ElementTree
LazyConcatenation
re
wordpunct_tokenize
os
stanford_segmenter
concat
ZipFilePathPointer
WordPunctTokenizer
LineTokenizer
texttiling
py25
word_tokenize
TreebankWordTokenizer
CorpusReader
StreamBackedCorpusView
sexpr_tokenize
nltk
simple
PortugueseCategorizedPlaintextCorpusReader
RegexpTokenizer
mwe
regexp
find_corpus_fileids
CategorizedPlaintextCorpusReader
isinstance
SeekableUnicodeStreamReader
AbstractLazySequence
regexp_tokenize
defaultdict
read_wordpunct_block
punkt
SyntaxCorpusReader
TextTilingTokenizer
StanfordTokenizer
ConcatenatedCorpusView
pickle
text_type
TweetTokenizer
read_blankline_block
string_span_tokenize
bisect
slice_bounds
read_regexp_block
codecs
PathPointer
casual_tokenize
api
ValueError
tempfile
read_whitespace_block
EuroparlCorpusReader
line_tokenize
MWETokenizer
PlaintextCorpusReader
stanford
util
unicode_literals
CategorizedCorpusReader
NotImplementedError
WhitespaceTokenizer
tagged_treebank_para_block_reader
casual
string_types
sexpr
ReppTokenizer
